# 🏆 Best Hugging Face Models for Coding & Search (2025)

*Comprehensive rankings excluding Chinese-based and Meta models*

---

## 🚀 **Specialized Coding Models**

### **🥇 Top Tier (90-100 Score)**

| Rank | Model | Hugging Face ID | Size | HumanEval | License | Best For |
|------|-------|----------------|------|-----------|---------|----------|
| **1** | **Codestral 25.01** ⭐ | `mistralai/Codestral-25.01` | 22B | **86.6%** | Commercial* | State-of-the-art code completion |
| **2** | **Codestral Original** | `mistralai/Codestral-22B` | 22B | **81.1%** | Commercial* | Production code generation |
| **3** | **StarCoder2-15B** | `bigcode/starcoder2-15b` | 15B | **35%** | OpenRAIL-M | 600+ languages, enterprise |
| **4** | **Codestral Mamba 7B** | `mistralai/Codestral-Mamba-7B` | 7B | **75.0%** | Commercial* | Memory-efficient, long sequences |

*Commercial license available from Mistral AI

### **🥈 High Performance (80-89 Score)**

| Rank | Model | Hugging Face ID | Size | HumanEval | License | Best For |
|------|-------|----------------|------|-----------|---------|----------|
| **5** | **CodeT5+-16B** | `Salesforce/codet5p-16b` | 16B | **35%** | Apache 2.0 | Code documentation, translation |
| **6** | **Microsoft Phi-4** | `microsoft/Phi-4` | 14B | **32%** | Apache 2.0 | Mathematical coding, reasoning |
| **7** | **StarCoder2-7B** | `bigcode/starcoder2-7b` | 7B | **30%** | OpenRAIL-M | Resource-conscious deployment |
| **8** | **Replit Code v1.5** | `replit/replit-code-v1_5-3b` | 3.3B | **28%** | Apache 2.0 | Interactive assistants, edge |

### **🥉 Solid Choices (70-79 Score)**

| Rank | Model | Hugging Face ID | Size | HumanEval | License | Best For |
|------|-------|----------------|------|-----------|---------|----------|
| **9** | **CodeGen2-7B** | `Salesforce/codegen2-7B` | 7B | **25%** | Apache 2.0 | Educational tools, conversations |
| **10** | **Mistral-7B-Instruct-v0.2** | `mistralai/Mistral-7B-Instruct-v0.2` | 7B | **~20%** | Apache 2.0 | General programming assistance |
| **11** | **CodeT5+-220M** | `Salesforce/codet5p-220m` | 220M | **22%** | Apache 2.0 | Lightweight, custom fine-tuning |
| **12** | **IBM Granite-8B-Code** | `ibm-granite/granite-8b-code-base` | 8B | **20%** | Apache 2.0 | Enterprise, compliance-critical |

---

## 🤖 **General Purpose Models (with Strong Coding)**

### **🌟 Latest Mistral Small Series**

| Rank | Model | Hugging Face ID | Size | HumanEval+ | Generation | Best For |
|------|-------|----------------|------|------------|------------|----------|
| **1** | **Mistral Small 3.2 Instruct** ⭐ | `mistralai/Mistral-Small-3.2-24B-Instruct-2506` | 24B | **92.9%** | June 2025 | **RECOMMENDED** - Production agents |
| **2** | **Mistral Small 3.2 Base** | `mistralai/Mistral-Small-3.2-24B-Base-2506` | 24B | - | June 2025 | Custom fine-tuning, latest arch |
| **3** | **Mistral Small 3.1 Instruct** | `mistralai/Mistral-Small-3.1-24B-Instruct-2503` | 24B | **88.9%** | March 2025 | Multimodal, vision tasks |
| **4** | **Mistral Small 3.1 Base** | `mistralai/Mistral-Small-3.1-24B-Base-2503` | 24B | - | March 2025 | Multimodal fine-tuning |
| **5** | **Mistral Small 3.0 Instruct** | `mistralai/Mistral-Small-24B-Instruct-2501` | 24B | **85%+** | January 2025 | Proven enterprise deployment |
| **6** | **Mistral Small 3.0 Base** | `mistralai/Mistral-Small-24B-Base-2501` | 24B | - | January 2025 | Research, foundation model |

### **💡 Lightweight Options**

| Rank | Model | Hugging Face ID | Size | HumanEval | Best For |
|------|-------|----------------|------|-----------|----------|
| **7** | **Mistral-7B-Instruct-v0.3** | `mistralai/Mistral-7B-Instruct-v0.3` | 7B | **~25%** | Function calling, tool use |
| **8** | **Mistral-7B-Instruct-v0.2** | `mistralai/Mistral-7B-Instruct-v0.2` | 7B | **~20%** | General programming assistance |

---

## 🔍 **Search & Retrieval Models**

### **🎯 State-of-the-Art**

| Rank | Model | Hugging Face ID | Size | MTEB Score | Best For |
|------|-------|----------------|------|------------|----------|
| **1** | **NVIDIA NV-Embed-v2** | `nvidia/NV-Embed-v2` | 7B | **72.31** | Enterprise search, highest accuracy |
| **2** | **all-mpnet-base-v2** | `sentence-transformers/all-mpnet-base-v2` | 110M | **63.3** | General semantic search |
| **3** | **NVIDIA NV-Embed-v1** | `nvidia/NV-Embed-v1` | 7B | **69.1** | Proven production systems |

### **⚡ High-Speed Options**

| Rank | Model | Hugging Face ID | Size | MTEB Score | Best For |
|------|-------|----------------|------|------------|----------|
| **4** | **ms-marco-MiniLM-L6-v2** | `cross-encoder/ms-marco-MiniLM-L6-v2` | 23M | - | Reranking, two-stage retrieval |
| **5** | **all-MiniLM-L6-v2** | `sentence-transformers/all-MiniLM-L6-v2` | 23M | **56.3** | High-throughput, real-time search |
| **6** | **mxbai-embed-large-v1** | `mixedbread-ai/mxbai-embed-large-v1` | 335M | **64.6** | Flexible embedding dimensions |

---

## 📋 **Quick Reference Guide**

### **🔥 Top Recommendations by Use Case**

#### **For Coding:**
- **🏆 Best Overall**: Codestral 25.01 (if budget allows commercial license)
- **🆓 Best Open Source**: StarCoder2-15B (BigCode OpenRAIL-M)
- **💰 Best Apache 2.0**: Microsoft Phi-4 or CodeT5+-16B
- **⚡ Fastest**: Replit Code v1.5-3B

#### **For General Purpose + Coding:**
- **🌟 Latest & Greatest**: Mistral Small 3.2 24B Instruct ⭐
- **👁️ With Vision**: Mistral Small 3.1 24B Instruct
- **🔒 Most Stable**: Mistral Small 3.0 24B Instruct

#### **For Search & Retrieval:**
- **🎯 Highest Accuracy**: NVIDIA NV-Embed-v2
- **⚖️ Best Balance**: all-mpnet-base-v2
- **🚀 Fastest**: all-MiniLM-L6-v2

### **📜 License Overview**

| License Type | Commercial Use | Modification | Distribution | Restrictions |
|--------------|----------------|--------------|--------------|--------------|
| **Apache 2.0** | ✅ Full | ✅ Yes | ✅ Yes | Minimal (attribution only) |
| **BigCode OpenRAIL-M** | ✅ Yes | ✅ Yes | ✅ Yes | Ethical use restrictions |
| **Mistral Commercial** | 💰 Paid | ✅ Yes | ✅ Yes | Enterprise licensing |

### **💾 Hardware Requirements**

#### **Memory Requirements (approximate)**
- **3B models**: 6-8 GB VRAM
- **7B models**: 14-16 GB VRAM  
- **15B models**: 30-32 GB VRAM
- **24B models**: 48-55 GB VRAM

#### **Recommended GPUs**
- **Small models (≤7B)**: RTX 4090, RTX 3090
- **Medium models (15B)**: A100 40GB, H100
- **Large models (24B)**: A100 80GB, H100, or multiple GPUs

### **🚀 Deployment Options**

#### **Self-Hosting (Fully Open)**
- **StarCoder2 series** (BigCode OpenRAIL-M)
- **All Apache 2.0 models** (Phi-4, CodeT5+, Granite, etc.)
- **Mistral Small 24B series** (Apache 2.0)

#### **API Access**
- **Codestral 25.01**: Mistral AI API, Azure, Google Cloud
- **StarCoder2**: Hugging Face Inference Endpoints
- **Search models**: Sentence Transformers, direct inference

---

## 🎯 **Final Recommendations**

### **🥇 Best Overall Choices**

1. **For Production Coding**: **Mistral Small 3.2 24B Instruct** ⭐
   - Latest technology, 92.9% HumanEval+, Apache 2.0
   
2. **For Specialized Coding**: **Codestral 25.01**
   - #1 performance, 86.6% HumanEval, commercial license

3. **For Open Source Coding**: **StarCoder2-15B**
   - 600+ languages, proven performance, OpenRAIL-M

4. **For Search**: **NVIDIA NV-Embed-v2**
   - State-of-the-art accuracy, enterprise-grade

### **💡 Pro Tips**

- **Start with Mistral Small 3.2 24B** for most use cases
- **Use base models** if you plan to fine-tune
- **Consider hardware costs** when choosing model size
- **Apache 2.0 models** offer maximum flexibility
- **Always check license requirements** for your specific use case

---

*Last updated: January 2025 | Excludes Chinese-based and Meta models as requested*